{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlrose_hiive as mlrh\n",
    "import mlrose \n",
    "import matplotlib.pyplot as plt\n",
    "my_random_state = 318\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,plot_confusion_matrix\n",
    "# from sklearn.datasets import load_iris\n",
    "algorithms = ['GD','RHC', 'SA', 'GA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22792, 14) (9769, 14) (22792,) (9769,)\n"
     ]
    }
   ],
   "source": [
    "##### Adult Income\n",
    "### http://archive.ics.uci.edu/ml/datasets/Adult\n",
    "data = pd.read_csv('datafiles/adult.csv')\n",
    "data\n",
    "\n",
    "y_data_raw = data.income\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_data_raw.values.tolist())\n",
    "y_data = le.transform(y_data_raw)\n",
    "\n",
    "\n",
    "x_data_raw = data.loc[:,'age':'native-country']\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(x_data_raw.values.tolist())\n",
    "x_data = enc.transform(x_data_raw)\n",
    "\n",
    "# temp = enc.inverse_transform(x_data)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=0.7, random_state=my_random_state, shuffle=True)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = np.zeros(4)\n",
    "test_accuracies = np.zeros(4)\n",
    "optim_time = np.zeros(4)\n",
    "train_time = np.zeros(4)\n",
    "test_time = np.zeros(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network object and fit object\n",
    "tic = time.perf_counter() \n",
    "nn = mlrose.NeuralNetwork(hidden_nodes = [20,20,20], # activation = 'relu', \n",
    "                                 algorithm = 'gradient_descent', # max_iters = 1000, \n",
    "                                 learning_rate = 0.001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "toc = time.perf_counter() \n",
    "optim_time[0] = toc-tic\n",
    "print(f\"optimization time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "\n",
    "tic = time.perf_counter() \n",
    "nn.fit(x_train, y_train)\n",
    "toc = time.perf_counter() \n",
    "train_time[0] = toc-tic\n",
    "print(f\"training time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "print(\"Value of loss function for fitted weights when fit is performed\\n\",nn.loss)\n",
    "# print(\"fitted_weights\", nn_gd.fitted_weights)\n",
    "# nn.fitted_weights\n",
    "nn.fitted_weights.shape\n",
    "# learning_rate = 0.1\n",
    "# Value of loss function for fitted weights when fit is performed 1.3862943611198906\n",
    "# array([-5.        , -0.31964703, -5.        , ...,  5.        ,\n",
    "#        -5.        , -0.11450284])\n",
    "\n",
    "# learning_rate = 0.001\n",
    "# Value of loss function for fitted weights when fit is performed 0.25105686815160916\n",
    "# array([ 0.09052286, -0.31964703, -0.67567475, ...,  1.29516855,\n",
    "#         0.22538836,  0.15522131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = nn.predict(x_train)\n",
    "y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(y_train_accuracy)\n",
    "train_accuracies[0] = y_train_accuracy\n",
    "# 0.9319148936170213 @ learning_rate = 0.001\n",
    "# 0.4 @ learning rate = 0.1\n",
    "\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "\n",
    "tic = time.perf_counter() \n",
    "y_test_pred = nn.predict(x_test)\n",
    "toc = time.perf_counter() \n",
    "test_time[0] = toc-tic\n",
    "print(f\"testing time {toc - tic} seconds\")\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(y_test_accuracy)\n",
    "test_accuracies[0] = y_test_accuracy\n",
    "# 0.9306930693069307 @ learning_rate = 0.001\n",
    "# 0.48514851485148514 @ learning_rate = 0.1\n",
    "\n",
    "# nn_gd.predicted_probs\n",
    "\n",
    "\n",
    "# plot_confusion_matrix(nn, x_test, y_test,normalize='true',cmap=plt.cm.Blues)\n",
    "# plt.savefig('NN/NN_GD_confusion_matrix_normalized.png') \n",
    "# plt.show()\n",
    "\n",
    "nn_gd = nn ## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. random_hill_climb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter() \n",
    "nn = mlrose.NeuralNetwork(hidden_nodes = [20,20,20], # activation = 'relu', \n",
    "                                 algorithm = 'random_hill_climb', max_iters = 5000, \n",
    "                                 restarts = 3, #learning_rate = 0.001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "toc = time.perf_counter() \n",
    "optim_time[1] = toc-tic\n",
    "print(f\"optimization time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "\n",
    "tic = time.perf_counter() \n",
    "nn.fit(x_train, y_train)\n",
    "toc = time.perf_counter() \n",
    "train_time[1] = toc-tic\n",
    "print(f\"training time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "print(\"Value of loss function for fitted weights when fit is performed\\n\",nn.loss)\n",
    "# print(\"fitted_weights\", nn_gd.fitted_weights)\n",
    "# nn.fitted_weights\n",
    "nn.fitted_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = nn.predict(x_train)\n",
    "y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(y_train_accuracy)\n",
    "train_accuracies[1] = y_train_accuracy\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "\n",
    "tic = time.perf_counter() \n",
    "y_test_pred = nn.predict(x_test)\n",
    "toc = time.perf_counter() \n",
    "test_time[1] = toc-tic\n",
    "print(f\"testing time {toc - tic} seconds\")\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(y_test_accuracy)\n",
    "test_accuracies[1] = y_test_accuracy\n",
    "\n",
    "# nn_gd.predicted_probs\n",
    "\n",
    "\n",
    "nn_rhc = nn ## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies,test_accuracies, optim_time, train_time, test_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simulated_annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter() \n",
    "nn = mlrose.NeuralNetwork(hidden_nodes = [20,20,20], # activation = 'relu', \n",
    "                                 algorithm = 'simulated_annealing', max_iters = 10000, \n",
    "                                 #learning_rate = 0.001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "toc = time.perf_counter() \n",
    "optim_time[2] = toc-tic\n",
    "print(f\"optimization time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "\n",
    "tic = time.perf_counter() \n",
    "nn.fit(x_train, y_train)\n",
    "toc = time.perf_counter() \n",
    "train_time[2] = toc-tic\n",
    "print(f\"training time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "print(\"Value of loss function for fitted weights when fit is performed\\n\",nn.loss)\n",
    "# print(\"fitted_weights\", nn_gd.fitted_weights)\n",
    "# nn.fitted_weights\n",
    "nn.fitted_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = nn.predict(x_train)\n",
    "y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(y_train_accuracy)\n",
    "train_accuracies[2] = y_train_accuracy\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "\n",
    "tic = time.perf_counter() \n",
    "y_test_pred = nn.predict(x_test)\n",
    "toc = time.perf_counter() \n",
    "test_time[2] = toc-tic\n",
    "print(f\"testing time {toc - tic} seconds\")\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(y_test_accuracy)\n",
    "test_accuracies[2] = y_test_accuracy\n",
    "\n",
    "# nn_gd.predicted_probs\n",
    "\n",
    "\n",
    "nn_sa = nn ## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies,test_accuracies, optim_time, train_time, test_time\n",
    "# (array([0.93191489, 0.95744681, 0.88510638, 0.        ]),\n",
    "#  array([0.93069307, 0.92079208, 0.91089109, 0.        ]),\n",
    "#  array([7.36000002e-05, 7.58999995e-05, 8.43999997e-05, 0.00000000e+00]),\n",
    "#  array([ 0.3091845, 26.5170176,  9.956555 ,  0.       ]),\n",
    "#  array([0.000536 , 0.0003569, 0.0004006, 0.       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# genetic_alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter() \n",
    "nn = mlrose.NeuralNetwork(hidden_nodes = [20,20,20], # activation = 'relu', \n",
    "                                 algorithm = 'genetic_alg', max_iters = 1000, \n",
    "                                 #learning_rate = 0.001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "toc = time.perf_counter() \n",
    "optim_time[3] = toc-tic\n",
    "print(f\"optimization time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "\n",
    "tic = time.perf_counter() \n",
    "nn.fit(x_train, y_train)\n",
    "toc = time.perf_counter() \n",
    "train_time[3] = toc-tic\n",
    "print(f\"training time {toc - tic} seconds\")\n",
    "print()\n",
    "\n",
    "print(\"Value of loss function for fitted weights when fit is performed\\n\",nn.loss)\n",
    "# print(\"fitted_weights\", nn_gd.fitted_weights)\n",
    "# nn.fitted_weights\n",
    "nn.fitted_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = nn.predict(x_train)\n",
    "y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(y_train_accuracy)\n",
    "train_accuracies[3] = y_train_accuracy\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "\n",
    "tic = time.perf_counter() \n",
    "y_test_pred = nn.predict(x_test)\n",
    "toc = time.perf_counter() \n",
    "test_time[3] = toc-tic\n",
    "print(f\"testing time {toc - tic} seconds\")\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(y_test_accuracy)\n",
    "test_accuracies[3] = y_test_accuracy\n",
    "\n",
    "# nn_gd.predicted_probs\n",
    "\n",
    "\n",
    "nn_ga = nn ## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies,test_accuracies, optim_time, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy & Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html\n",
    "\n",
    "width = 0.4  # the width of the bars\n",
    "x = np.arange(len(algorithms))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, train_accuracies, width, label='train')\n",
    "rects2 = ax.bar(x + width/2, test_accuracies, width, label='test')\n",
    "\n",
    "plt.gca().set_ylim(0.6, 1.0)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Prediction Accuracy')\n",
    "ax.set_title('prediction accuracy on training/testing set')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['GD','RHC','SA','GA'])\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:0.2f}%'.format(height*100),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('NN/accuracy.png') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "rects = ax.bar(['GD','RHC','SA','GA'],train_time)\n",
    "\n",
    "\n",
    "def autolabel2(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:0.4f}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "autolabel2(rects)\n",
    "\n",
    "# plt.ylim(.1, 2000)\n",
    "plt.title('Training time (logscale)')\n",
    "ax.set_yscale('log')\n",
    "# plt.xlabel('classifiers')\n",
    "plt.ylabel(\"training time [second]\")\n",
    "plt.savefig('NN/training_time.png') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitness curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numiters = [100,500,1000,2000,5000,10000]\n",
    "train_accu_fit = np.zeros((4,6))\n",
    "train_time_fit = np.zeros((4,6))\n",
    "test_accu_fit = np.zeros((4,6))\n",
    "algorithms = ['gradient_descent','random_hill_climb','simulated_annealing','genetic_alg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time 44.269546399999854 seconds\n",
      "0.7609248859248859\n",
      "0.7551438222950149\n",
      "training time 40.7635408000001 seconds\n",
      "0.7609248859248859\n",
      "0.7551438222950149\n",
      "training time 39.69460509999999 seconds\n",
      "0.7609248859248859\n",
      "0.7551438222950149\n",
      "training time 39.30813360000002 seconds\n",
      "0.7609248859248859\n",
      "0.7551438222950149\n",
      "training time 39.93011000000024 seconds\n",
      "0.7609248859248859\n",
      "0.7551438222950149\n",
      "training time 39.823226100000284 seconds\n",
      "0.7609248859248859\n",
      "0.7551438222950149\n"
     ]
    }
   ],
   "source": [
    "# gradient_descent\n",
    "for i in range(len(numiters)):\n",
    "    it = numiters[i]\n",
    "    nn = mlrose.NeuralNetwork(hidden_nodes = [90,90,90,90], # activation = 'relu', \n",
    "                                 algorithm = 'gradient_descent', max_iters = it, \n",
    "                                 learning_rate = 0.0001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "    \n",
    "    tic = time.perf_counter() \n",
    "    nn.fit(x_train, y_train)\n",
    "    toc = time.perf_counter() \n",
    "    train_time_fit[0][i] = toc - tic\n",
    "    print(f\"training time {toc - tic} seconds\")\n",
    "    \n",
    "    y_train_pred = nn.predict(x_train)\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(y_train_accuracy)\n",
    "    train_accu_fit[0][i] = y_train_accuracy\n",
    "    \n",
    "    y_test_pred = nn.predict(x_test)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(y_test_accuracy)\n",
    "    test_accu_fit[0][i] = y_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time 61.89317280000023 seconds\n",
      "0.31221481221481223\n",
      "0.3170232367693725\n",
      "training time 305.75816529999975 seconds\n",
      "0.7918567918567918\n",
      "0.7886170539461562\n",
      "training time 598.2730277999999 seconds\n",
      "0.7926026676026676\n",
      "0.7886170539461562\n",
      "training time 1021.1213736999998 seconds\n",
      "0.7926465426465427\n",
      "0.7893336063056607\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ec63b7089afb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_time_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\neural.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, init_weights)\u001b[0m\n\u001b[0;32m    550\u001b[0m                                           \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                                           \u001b[0mrestarts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                                           curve=self.curve)\n\u001b[0m\u001b[0;32m    553\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                     current_weights, current_loss = random_hill_climb(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\algorithms.py\u001b[0m in \u001b[0;36mrandom_hill_climb\u001b[1;34m(problem, max_attempts, max_iters, restarts, init_state, curve, random_state)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;31m# Find random neighbor and evaluate fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_neighbor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[0mnext_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[1;31m# If best neighbor is an improvement,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\opt_probs.py\u001b[0m in \u001b[0;36meval_fitness\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"state length must match problem length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\neural.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;31m# Transform outputs to get inputs for next layer (or final preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\activation.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(x, deriv)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m     51\u001b[0m     \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mfx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mderiv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RHC\n",
    "for i in range(len(numiters)):\n",
    "    it = numiters[i]\n",
    "    nn = mlrose.NeuralNetwork(hidden_nodes = [90,90,90,90], # activation = 'relu', \n",
    "                                 algorithm = algorithms[1], max_iters = it, \n",
    "                                 restarts = 3,#learning_rate = 0.001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "    \n",
    "    tic = time.perf_counter() \n",
    "    nn.fit(x_train, y_train)\n",
    "    toc = time.perf_counter() \n",
    "    train_time_fit[1][i] = toc - tic\n",
    "    print(f\"training time {toc - tic} seconds\")\n",
    "    \n",
    "    y_train_pred = nn.predict(x_train)\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(y_train_accuracy)\n",
    "    train_accu_fit[1][i] = y_train_accuracy\n",
    "    \n",
    "    y_test_pred = nn.predict(x_test)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(y_test_accuracy)\n",
    "    test_accu_fit[1][i] = y_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5000\n",
      "training time 1219.3594465999995 seconds\n",
      "0.7947525447525448\n",
      "0.7888217831917289\n",
      "5\n",
      "10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-013b863c69c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtrain_time_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\neural.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, init_weights)\u001b[0m\n\u001b[0;32m    575\u001b[0m                     \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m                     \u001b[0minit_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m                     curve=self.curve)\n\u001b[0m\u001b[0;32m    578\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m                 fitted_weights, loss = simulated_annealing(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\algorithms.py\u001b[0m in \u001b[0;36msimulated_annealing\u001b[1;34m(problem, schedule, max_attempts, max_iters, init_state, curve, random_state)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;31m# Find random neighbor and evaluate fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_neighbor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mnext_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;31m# Calculate delta E and change prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\opt_probs.py\u001b[0m in \u001b[0;36meval_fitness\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"state length must match problem length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\neural.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;31m# Transform outputs to get inputs for next layer (or final preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\activation.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(x, deriv)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mValue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mat\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mfx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(a, order)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m--> 775\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;31m# Basic operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SA\n",
    "for i in range(4,len(numiters)):\n",
    "    it = numiters[i]\n",
    "    print(i)\n",
    "    print(it)\n",
    "    nn = mlrose.NeuralNetwork(hidden_nodes = [90,90,90,90], # activation = 'relu', \n",
    "                                 algorithm = algorithms[2], max_iters = it, \n",
    "                                 #learning_rate = 0.001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "    \n",
    "    tic = time.perf_counter() \n",
    "    nn.fit(x_train, y_train)\n",
    "    toc = time.perf_counter() \n",
    "    train_time_fit[2][i] = toc - tic\n",
    "    print(f\"training time {toc - tic} seconds\")\n",
    "    \n",
    "    y_train_pred = nn.predict(x_train)\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(y_train_accuracy)\n",
    "    train_accu_fit[2][i] = y_train_accuracy\n",
    "    \n",
    "    y_test_pred = nn.predict(x_test)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(y_test_accuracy)\n",
    "    test_accu_fit[2][i] = y_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6b3b6562a941>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_time_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\neural.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, init_weights)\u001b[0m\n\u001b[0;32m    595\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m                     curve=self.curve)\n\u001b[0m\u001b[0;32m    598\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                 fitted_weights, loss = genetic_alg(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\algorithms.py\u001b[0m in \u001b[0;36mgenetic_alg\u001b[1;34m(problem, pop_size, mutation_prob, max_attempts, max_iters, curve, random_state)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Create offspring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mchild\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreproduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutation_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             \u001b[0mnext_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlrose\\opt_probs.py\u001b[0m in \u001b[0;36mreproduce\u001b[1;34m(self, parent_1, parent_2, mutation_prob)\u001b[0m\n\u001b[0;32m    836\u001b[0m             \u001b[0m_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0mchild\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m             \u001b[0mchild\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m             \u001b[0mchild\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GA\n",
    "for i in range(len(numiters)):\n",
    "    it = numiters[i]\n",
    "    nn = mlrose.NeuralNetwork(hidden_nodes = [90,90,90,90], # activation = 'relu', \n",
    "                                 algorithm = algorithms[3], max_iters = it, \n",
    "                                 #learning_rate = 0.001, # bias = True, is_classifier = True, \n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \n",
    "                                 random_state = my_random_state, curve = True)\n",
    "    \n",
    "    tic = time.perf_counter() \n",
    "    nn.fit(x_train, y_train)\n",
    "    toc = time.perf_counter() \n",
    "    train_time_fit[3][i] = toc - tic\n",
    "    print(f\"training time {toc - tic} seconds\")\n",
    "    \n",
    "    y_train_pred = nn.predict(x_train)\n",
    "    y_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(y_train_accuracy)\n",
    "    train_accu_fit[3][i] = y_train_accuracy\n",
    "    \n",
    "    y_test_pred = nn.predict(x_test)\n",
    "    y_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(y_test_accuracy)\n",
    "    test_accu_fit[3][i] = y_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.76092489, 0.76092489, 0.76092489, 0.76092489, 0.76092489,\n",
       "         0.76092489],\n",
       "        [0.31221481, 0.79185679, 0.79260267, 0.79264654, 0.        ,\n",
       "         0.        ],\n",
       "        [0.24271674, 0.29308529, 0.78900491, 0.78939979, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[  44.2695464,   40.7635408,   39.6946051,   39.3081336,\n",
       "           39.93011  ,   39.8232261],\n",
       "        [  61.8931728,  305.7581653,  598.2730278, 1021.1213737,\n",
       "            0.       ,    0.       ],\n",
       "        [  27.2996384,  132.2044536,  256.1663907,  512.7198243,\n",
       "            0.       ,    0.       ],\n",
       "        [   0.       ,    0.       ,    0.       ,    0.       ,\n",
       "            0.       ,    0.       ]]),\n",
       " array([[0.75514382, 0.75514382, 0.75514382, 0.75514382, 0.75514382,\n",
       "         0.75514382],\n",
       "        [0.31702324, 0.78861705, 0.78861705, 0.78933361, 0.        ,\n",
       "         0.        ],\n",
       "        [0.2485413 , 0.29675504, 0.7861603 , 0.78697922, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        ]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "\n",
    "train_accu_fit,train_time_fit,test_accu_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test accuracy\n",
    "plt.figure()\n",
    "plt.semilogx(numiters, test_accu_fit[0], label = 'GD')\n",
    "plt.semilogx(numiters, test_accu_fit[1], label = 'RHC')\n",
    "plt.semilogx(numiters, test_accu_fit[2], label = 'SA')\n",
    "plt.semilogx(numiters[0:2], test_accu_fit[3][0:2], label = 'GA')\n",
    "\n",
    "\n",
    "plt.title('Fitness curve for NN - test accuracy')\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.savefig('NN/fitness_testaccuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numiters[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train accuracy\n",
    "plt.figure()\n",
    "plt.semilogx(numiters, train_accu_fit[0], label = 'GD')\n",
    "plt.semilogx(numiters, train_accu_fit[1], label = 'RHC')\n",
    "plt.semilogx(numiters, train_accu_fit[2], label = 'SA')\n",
    "plt.semilogx(numiters[0:2], train_accu_fit[3][0:2], label = 'GA')\n",
    "\n",
    "\n",
    "plt.title('Fitness curve for NN - train accuracy')\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.savefig('NN/fitness_trainaccuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train time\n",
    "plt.figure()\n",
    "plt.semilogx(numiters, train_time_fit[0], label = 'GD')\n",
    "plt.semilogx(numiters, train_time_fit[1], label = 'RHC')\n",
    "plt.semilogx(numiters, train_time_fit[2], label = 'SA')\n",
    "plt.semilogx(numiters[0:2], train_time_fit[3][0:2], label = 'GA')\n",
    "\n",
    "\n",
    "plt.title('Fitness curve for NN - training time (log-log scale)')\n",
    "plt.xlabel('max_iter')\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"time [second]\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.savefig('NN/fitness_traintime.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
